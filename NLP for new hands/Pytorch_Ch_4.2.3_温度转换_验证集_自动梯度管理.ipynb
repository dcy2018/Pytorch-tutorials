{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Traing loss  53.54, Validation loss  201.05\n",
      "Epoch 2, Traing loss  30.57, Validation loss  115.44\n",
      "Epoch 3, Traing loss  25.55, Validation loss  85.46\n",
      "Epoch 500, Traing loss  7.77, Validation loss  21.53\n",
      "Epoch 1000, Traing loss  4.16, Validation loss  9.28\n",
      "Epoch 1500, Traing loss  3.38, Validation loss  5.33\n",
      "Epoch 2000, Traing loss  3.21, Validation loss  3.87\n",
      "Epoch 2500, Traing loss  3.17, Validation loss  3.27\n",
      "Epoch 3000, Traing loss  3.16, Validation loss  3.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.0943, -16.0027], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "\n",
    "#随机获取训练集与验证集索引\n",
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "#train_indices, val_indices\n",
    "#(tensor([ 0,  5,  8,  1, 10,  7,  9,  4,  6]), tensor([3, 2])) #结果随机\n",
    "\n",
    "#根据索引划分训练集与验证集\n",
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "\n",
    "val_t_u = t_u[val_indices]\n",
    "val_t_c = t_c[val_indices]\n",
    "\n",
    "#将t_u进行规范化\n",
    "train_t_un = 0.1 * train_t_u\n",
    "val_t_un = 0.1 *val_t_u\n",
    "\n",
    "def model(t_u, w, b):\n",
    "    return w*t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()\n",
    "\n",
    "def calc_forward(t_u, t_c, is_train): #is_train用来设定是否自动求导\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "    return loss\n",
    "\n",
    "def training_loop(n_epochs, optimizer, params,\n",
    "                  train_t_u, val_t_u, train_t_c, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        train_loss = calc_forward(train_t_u, train_t_c, True)\n",
    "        val_loss = calc_forward(val_t_u, val_t_c, False)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print('Epoch %d, Traing loss % .2f, Validation loss % .2f'%(\n",
    "                    epoch, float(train_loss), float(val_loss)))\n",
    "    return params\n",
    "\n",
    "params = torch.tensor([1.0, 0.0], requires_grad = True) #初始化参数并激活梯度\n",
    "learning_rate = 1e-2 #设置学习率\n",
    "optimizer = optim.SGD([params], lr = learning_rate) #设定优化器\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 3000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    train_t_u = train_t_un,\n",
    "    val_t_u = val_t_un,\n",
    "    train_t_c = train_t_c,\n",
    "    val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
